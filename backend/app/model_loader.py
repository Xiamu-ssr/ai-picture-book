import torch, logging
from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel
from transformers import CLIPVisionModelWithProjection

logger = logging.getLogger(__name__)


class GlobalModels:
    """å•ä¾‹ç¼“å­˜ï¼ŒFastAPI å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡"""
    pipe: StableDiffusionXLControlNetPipeline | None = None


def load_models(dtype=torch.float16):
    """
    1. SDXL base (vit-L)
    2. ControlNet Depth (å¯ later æ›¿æ¢ä¸º pose/lineart)
    3. IP-Adapter Style  (vit-L)
    4. IP-Adapter FaceID (vit-L)
    """
    logger.info("ğŸª„ è½½å…¥ SDXL-base")
    pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        controlnet=ControlNetModel.from_pretrained(
            "diffusers/controlnet-depth-sdxl-1.0", torch_dtype=dtype),
        torch_dtype=dtype,
    )

    logger.info("ğŸ­ è½½å…¥ Style & FaceID ä¸¤ä¸ª IP-Adapter")
    pipe.load_ip_adapter(
        # â‘  æ¯ä¸ª adapter çš„ä»“åº“ / æœ¬åœ°è·¯å¾„
        pretrained_model_name_or_path_or_dict=[
            "h94/IP-Adapter",          # style
            "h94/IP-Adapter-FaceID",   # faceid
        ],
        # â‘¡ å„è‡ªå­æ–‡ä»¶å¤¹ï¼ˆä¸ä¸Šé¢ä¸€ä¸€å¯¹åº”ï¼‰
        subfolder=["sdxl_models", ""],
        # â‘¢ å„è‡ªçš„æƒé‡æ–‡ä»¶
        weight_name=[
            "ip-adapter_sdxl.bin",
            "ip-adapter-faceid_sdxl.bin",  # ViT-L
        ],
        # å¦‚æœæ˜¾å­˜ç´§å¼ å¯åŠ ï¼šlow_cpu_mem_usage=True
    )

    # pipe.enable_attention_slicing()
    pipe.to("cuda" if torch.cuda.is_available() else "cpu")

    GlobalModels.pipe = pipe
